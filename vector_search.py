import faiss
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")

# ğŸ”½ index.faiss ã¨ index.pkl ã«ã‚ã‚ã›ã¦ãƒ‘ã‚¹ã‚’ä¿®æ­£
index = faiss.read_index("index.faiss")
with open("index.pkl", "rb") as f:
    documents = pickle.load(f)

def search_similar_documents(query, top_k=3):
    embedding = model.encode([query])
    distances, indices = index.search(embedding, top_k)

    # ğŸ”½ ã“ã“ã‹ã‚‰ãƒ­ã‚°å‡ºåŠ›è¿½åŠ 
    print("ğŸ” ã‚¯ã‚¨ãƒª:", query)
    print("ğŸ” æ¤œç´¢çµæœã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹:", indices)
    print("ğŸ” è·é›¢ã‚¹ã‚³ã‚¢:", distances)

    results = [documents[i] for i in indices[0] if i < len(documents)]

    if not results:
        print("âš  æ¤œç´¢çµæœãŒç©ºã§ã™ï¼")
    else:
        print("âœ… å–å¾—ã—ãŸæ–‡æ›¸:\n", "\n---\n".join(results))

    return "\n---\n".join(results)

