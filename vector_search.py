import faiss
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆè»½é‡ã§é«˜é€Ÿãªæ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«ãƒ¢ãƒ‡ãƒ«ï¼‰
model = SentenceTransformer("all-MiniLM-L6-v2")

# FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨å¯¾å¿œæ–‡æ›¸ã®èª­ã¿è¾¼ã¿ï¼ˆapp.pyã¨åŒã˜éšå±¤ã«ç½®ãï¼‰
index = faiss.read_index("index.faiss")
with open("index.pkl", "rb") as f:
    documents = pickle.load(f)

def search_similar_documents(query, top_k=3):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«ä¼¼ãŸæ–‡æ›¸ã‚’ä¸Šä½ã‹ã‚‰å–å¾—"""
    embedding = model.encode([query])
    distances, indices = index.search(np.array(embedding).reshape(1, -1), top_k)

    # ğŸ” ãƒ­ã‚°å‡ºåŠ›ï¼ˆRenderã§ã‚‚ç¢ºèªå¯èƒ½ï¼‰
    print("ğŸ” ã‚¯ã‚¨ãƒª:", query)
    print("ğŸ” æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹:", indices)
    print("ğŸ” é¡ä¼¼ã‚¹ã‚³ã‚¢:", distances)

    results = [documents[i] for i in indices[0] if i < len(documents)]

    if not results:
        print("âš  æ¤œç´¢çµæœãªã—ï¼ˆresults ç©ºï¼‰")
        return "ï¼ˆå‚è€ƒæ–‡çŒ®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"

    print("âœ… å–å¾—æ–‡æ›¸:\n", "\n---\n".join(results))
    return "\n---\n".join(results)
